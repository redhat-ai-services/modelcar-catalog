model:
  mode: uri
  uri: oci://quay.io/redhat-ai-services/modelcar-catalog:granite-3.3-8b-instruct-accelerated
  args:
    - '--speculative-config={"model": "/mnt/models/granite-3.0-8b-instruct-accelerator", "method": "eagle3", "num_speculative_tokens": 4, "draft_tensor_parallel_size": 1}'

  env:
    - name: HF_HUB_OFFLINE
      value: "1"

servingRuntime:
  args:
    - --port=8080
    - --model=/mnt/models/granite-3.3-8b-instruct
